{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from gym import wrappers\n",
    "from torch import nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from src import utils as utils\n",
    "from src.model import SimpleRecurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# env_name = \"MiniGrid-FourRooms-v0\"\n",
    "env_name = \"MiniGrid-DoorKey-5x5-v0\"\n",
    "# env_name = \"MiniGrid-Empty-Random-5x5-v0\"\n",
    "env = utils.make_env(env_name)\n",
    "\n",
    "obs_space_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "plt.title('Game image')\n",
    "plt.imshow(env.render('rgb_array'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from src.a2c import A2CAlgo\n",
    "\n",
    "# os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "LOG_EACH = 30\n",
    "VIDEO_EACH = 400\n",
    "\n",
    "config = {\n",
    "    \"time\": 8,\n",
    "    \"n_games_mean\": 1,\n",
    "    \"max_reward\": 2,\n",
    "    \"device\": \"cpu\",\n",
    "    \"env\": env_name,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"emb_dim\": 128,\n",
    "    \"n_env\": 128,\n",
    "    \"gamma\": 0.9,\n",
    "\n",
    "    \"max_grad_norm\": 0.5,\n",
    "    \"lr\": 0.001,\n",
    "    \"value_loss_coef\": 1,\n",
    "    \"entropy_coef\": 0.01,\n",
    "}\n",
    "\n",
    "obs = env.reset()\n",
    "agent = SimpleRecurrent(\n",
    "    obs_space_shape,\n",
    "    n_actions,\n",
    "    config\n",
    ")\n",
    "for p in agent.parameters():\n",
    "    nn.init.uniform_(p, -0.1, 0.1)\n",
    "\n",
    "wandb.init(project=\"mlsh\",\n",
    "           monitor_gym=True,\n",
    "           name=f\"{env_name[9:]}\",\n",
    "           config=config,\n",
    "           dir=\"..\",\n",
    "           magic=True)\n",
    "wandb.watch(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "from src.env_pool import EnvPool\n",
    "pool = EnvPool(agent, lambda : utils.make_env(env_name), config[\"n_env\"])\n",
    "rollout_obs, rollout_actions, rollout_rewards, rollout_mask = pool.interact(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Actions shape:\", rollout_actions.shape)\n",
    "print(\"Rewards shape:\", rollout_rewards.shape)\n",
    "print(\"Mask shape:\", rollout_mask.shape)\n",
    "print(\"Observations shape: \", rollout_obs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "alg = A2CAlgo(agent, config[\"device\"], n_actions,\n",
    "              config[\"gamma\"],\n",
    "              config[\"max_grad_norm\"],\n",
    "              config[\"entropy_coef\"],\n",
    "              config[\"lr\"],\n",
    "              config[\"value_loss_coef\"])\n",
    "\n",
    "memory = list(pool.prev_memory_states)\n",
    "int_time = 0\n",
    "step_time = 0\n",
    "wandb_time = 0\n",
    "\n",
    "from time import time\n",
    "\n",
    "for i in tqdm(range(4000)):\n",
    "    memory = list(pool.prev_memory_states)\n",
    "    t = time()\n",
    "    rollout_obs, rollout_actions, rollout_rewards, rollout_mask = pool.interact(config[\"time\"])\n",
    "    int_time += time() - t\n",
    "    t = time()\n",
    "    loss, grad_norm, entropy, values, al, cl = alg.step(\n",
    "        rollout_obs, rollout_actions, rollout_rewards, rollout_mask, memory, config[\"gamma\"])\n",
    "    step_time += time() - t\n",
    "    t = time()\n",
    "    wandb.log({\n",
    "            \"rew\": np.mean(rollout_rewards),\n",
    "            \"values\": np.mean(values),\n",
    "            \"policy_loss\": al,\n",
    "            \"value_loss\": cl\n",
    "        }, commit=False, step=i)\n",
    "    wandb_time += time() - t\n",
    "\n",
    "    if i % LOG_EACH == 0:\n",
    "        reward = np.mean(utils.evaluate(agent, env, n_games=10))\n",
    "        log = {\n",
    "            \"rewards\": reward,\n",
    "            \"grad_norm\": grad_norm,\n",
    "            \"entropy\": entropy,\n",
    "            \"loss\": loss\n",
    "        }\n",
    "        wandb.log(log, step=i, commit=i%VIDEO_EACH==0)\n",
    "\n",
    "        # if i % VIDEO_EACH == 0:\n",
    "        #     env_monitor = wrappers.Monitor(env, directory=\"videos\", force=True)\n",
    "        #     rw = utils.evaluate(agent, env_monitor, n_games=config[\"n_games_mean\"],)\n",
    "        #     env_monitor.close()\n",
    "        if reward  >= config[\"max_reward\"]:\n",
    "            print(\"Your agent has just passed the minimum homework threshold\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLSH",
   "language": "python",
   "name": "mlsh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}